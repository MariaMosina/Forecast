{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc \n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor\n",
    "from lightgbm import LGBMRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"dataset_train.csv\", parse_dates=['date'])\n",
    "test = pd.read_csv(\"dataset_valid.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data and creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape(preds, target):\n",
    "    '''\n",
    "    Function to calculate SMAPE\n",
    "    '''\n",
    "    n = len(preds)\n",
    "    masked_arr = ~((preds == 0) & (target == 0))\n",
    "    preds, target = preds[masked_arr], target[masked_arr]\n",
    "    num = np.abs(preds - target)\n",
    "    denom = np.abs(preds) + np.abs(target)\n",
    "    smape_val = ( 200 * np.sum(num / denom)) / n\n",
    "    return smape_val\n",
    "\n",
    "def add_date_features(df):\n",
    "    df['year'] = df.date.dt.year\n",
    "    df['month'] = df.date.dt.month\n",
    "    df['weekofyear'] = df.date.dt.weekofyear\n",
    "    df['day'] = df.date.dt.day\n",
    "    df['quarter'] = df.date.dt.quarter\n",
    "    df['dayofyear'] = df.date.dt.dayofyear\n",
    "    df['dayofweek'] = df.date.dt.dayofweek\n",
    "#     df['is_month_start'] = df.date.dt.is_month_start\n",
    "#     df['is_month_end'] = df.date.dt.is_month_end\n",
    "#     df['is_quarter_start'] = df.date.dt.is_quarter_start\n",
    "#     df['is_quarter_end'] = df.date.dt.is_quarter_end\n",
    "    df['is_year_start'] = df.date.dt.is_year_start\n",
    "    df['is_year_end'] = df.date.dt.is_year_end\n",
    "\n",
    "    return df.copy()\n",
    "\n",
    "def meanf_(df, columns,  test_exist = True, test=None):\n",
    "    for i in columns:\n",
    "        meanf_column = 0\n",
    "        meanf_column = df.loc[:, [i, 'sales']].groupby(i).agg('mean').reset_index()\n",
    "        meanf_column.rename(columns={'sales':(\"meanf_\"+i)}, inplace=True)\n",
    "        df = pd.merge(df,meanf_column, on=i)\n",
    "        if (test_exist == True):\n",
    "            test = pd.merge(test,meanf_column, on=i, how = 'left')\n",
    "    if (test_exist == True):\n",
    "        return df, test\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_date_features(train)\n",
    "test = add_date_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = meanf_(df = train, columns = ['day', 'dayofweek', 'dayofyear', 'item', 'month', 'quarter', 'shop',\n",
    "       'weekofyear', 'year', #'is_month_start', 'is_month_end', \n",
    "                                            #'is_quarter_start', 'is_quarter_end'\n",
    "                                             'is_year_start', \n",
    "                                            'is_year_end'],\n",
    "                                           \n",
    "                     test_exist = True, test = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test months {4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Combined df shape:(913000, 25)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_months = set(test.month.unique())\n",
    "print('Test months', test_months)\n",
    "\n",
    "train['train_or_test'] = 'train'\n",
    "test['train_or_test'] = 'test'\n",
    "df = pd.concat([train,test], ignore_index=True)\n",
    "print('Combined df shape:{}'.format(df.shape))\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sales = df.sales.apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_mask = (df.year == 2016) & (df.month.isin(test_months))\n",
    "throw_mask = (df.year == 2017) & (~(df.month.isin(test_months)))\n",
    "df.loc[valid_mask, 'train_or_test'] = 'val'\n",
    "df.loc[throw_mask, 'train_or_test'] = 'no_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noise(scale, size):\n",
    "    return np.random.normal(\n",
    "        loc=0, # why is 0?\n",
    "        scale=scale, \n",
    "        size=size\n",
    "    )\n",
    "\n",
    "def lag_features(df, groupcols, target, lags):\n",
    "    g = df.groupby(groupcols)\n",
    "    for lag in lags:\n",
    "        name = '_'.join([target, 'lag', str(lag)])\n",
    "        df[name] = g[target].shift(lag).values + noise(50, len(df))\n",
    "    return df\n",
    "\n",
    "def rolling_mean(df, groupcols, target, windows, \n",
    "                 min_periods=2, shift=1, win_type=None):\n",
    "    g = df.groupby(groupcols)\n",
    "    for w in windows:\n",
    "        for s in shift:\n",
    "            name = '_'.join([target, 'rmean', str(w)])\n",
    "            df[name] = g[target].shift(s).rolling(w, min_periods, win_type=win_type).mean().values #+ noise(0.56, len(df))\n",
    "    return df\n",
    "\n",
    "def emw_mean(df, groupcols, target, alpha=[0.9], shift=[1]):\n",
    "    g = df.groupby(groupcols)\n",
    "    for a in alpha:\n",
    "        for s in shift:\n",
    "            name = '_'.join([target, 'lag', str(s), 'ewm', str(a)])\n",
    "            df[name] = g[target].shift(s).ewm(alpha=a).mean().values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = lag_features(\n",
    "#     df, \n",
    "#     groupcols=['shop','item'],\n",
    "#     target='sales', \n",
    "#     lags=[365, 365+7, 365-7, 365+14, 365-14, 365*2, 365*2+7, 365*2-7, 365*2+14, 365-14]\n",
    "# )#0.15\n",
    "\n",
    "# df = rolling_mean(\n",
    "#     df, \n",
    "#     groupcols=['shop','item'], \n",
    "#     target='sales', \n",
    "#     windows = [2, 3, 4, 5, 6, 7,],\n",
    "#     shift=[365, 365+7, 365-7, 365+14, 365-14],#, 365*2, 365*2+7, 365*2-7, 365*2+14, 365-14],\n",
    "#     win_type='triang'\n",
    "# )#0.17\n",
    "\n",
    "# df = emw_mean(\n",
    "#     df, \n",
    "#     groupcols=['shop','item'],\n",
    "#     target='sales', \n",
    "#     alpha=[0.99, 0.95, 0.9, 0.8, 0.7, 0.6, 0.5],\n",
    "#     shift=[365, 300]#, 365+7, 365-7, 365+14, 365-14]#, 365*2, 365*2+7, 365*2-7, 365*2+14, 365*2-14]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df['month']>=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = df.loc[df.train_or_test.isin(['train', 'val', 'test']), :]\n",
    "y_train = temp[temp.train_or_test == 'train']['sales'].values.reshape((-1))\n",
    "y_valid = temp[temp.train_or_test == 'val']['sales'].values.reshape((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = temp.loc[temp.train_or_test=='val', :]\n",
    "train = temp.loc[temp.train_or_test=='train', :]\n",
    "test = temp.loc[temp.train_or_test=='test', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = train.dropna().index\n",
    "train = train.loc[idx]\n",
    "y_train = train.sales[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['sales', 'train_or_test', 'date'], axis = 1)\n",
    "val = val.drop(['sales', 'train_or_test', 'date'], axis = 1)\n",
    "test = test.drop(['sales', 'train_or_test', 'date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137500, 22)\n",
      "(412500, 22)\n",
      "(137500, 22)\n"
     ]
    }
   ],
   "source": [
    "print(val.shape)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.528629\n",
      "Training until validation scores don't improve for 15 rounds.\n",
      "[2]\tvalid_0's rmse: 0.489428\n",
      "[3]\tvalid_0's rmse: 0.456164\n",
      "[4]\tvalid_0's rmse: 0.426496\n",
      "[5]\tvalid_0's rmse: 0.401199\n",
      "[6]\tvalid_0's rmse: 0.38024\n",
      "[7]\tvalid_0's rmse: 0.36059\n",
      "[8]\tvalid_0's rmse: 0.343879\n",
      "[9]\tvalid_0's rmse: 0.329093\n",
      "[10]\tvalid_0's rmse: 0.316697\n",
      "[11]\tvalid_0's rmse: 0.304837\n",
      "[12]\tvalid_0's rmse: 0.294521\n",
      "[13]\tvalid_0's rmse: 0.285846\n",
      "[14]\tvalid_0's rmse: 0.277192\n",
      "[15]\tvalid_0's rmse: 0.268181\n",
      "[16]\tvalid_0's rmse: 0.260371\n",
      "[17]\tvalid_0's rmse: 0.253361\n",
      "[18]\tvalid_0's rmse: 0.248344\n",
      "[19]\tvalid_0's rmse: 0.242887\n",
      "[20]\tvalid_0's rmse: 0.238854\n",
      "[21]\tvalid_0's rmse: 0.235091\n",
      "[22]\tvalid_0's rmse: 0.231937\n",
      "[23]\tvalid_0's rmse: 0.2266\n",
      "[24]\tvalid_0's rmse: 0.223432\n",
      "[25]\tvalid_0's rmse: 0.218856\n",
      "[26]\tvalid_0's rmse: 0.215468\n",
      "[27]\tvalid_0's rmse: 0.21179\n",
      "[28]\tvalid_0's rmse: 0.20921\n",
      "[29]\tvalid_0's rmse: 0.206058\n",
      "[30]\tvalid_0's rmse: 0.203426\n",
      "[31]\tvalid_0's rmse: 0.201257\n",
      "[32]\tvalid_0's rmse: 0.198226\n",
      "[33]\tvalid_0's rmse: 0.196531\n",
      "[34]\tvalid_0's rmse: 0.194516\n",
      "[35]\tvalid_0's rmse: 0.192531\n",
      "[36]\tvalid_0's rmse: 0.190667\n",
      "[37]\tvalid_0's rmse: 0.189322\n",
      "[38]\tvalid_0's rmse: 0.187868\n",
      "[39]\tvalid_0's rmse: 0.186964\n",
      "[40]\tvalid_0's rmse: 0.18584\n",
      "[41]\tvalid_0's rmse: 0.184818\n",
      "[42]\tvalid_0's rmse: 0.18391\n",
      "[43]\tvalid_0's rmse: 0.182139\n",
      "[44]\tvalid_0's rmse: 0.181342\n",
      "[45]\tvalid_0's rmse: 0.180748\n",
      "[46]\tvalid_0's rmse: 0.179942\n",
      "[47]\tvalid_0's rmse: 0.179459\n",
      "[48]\tvalid_0's rmse: 0.178918\n",
      "[49]\tvalid_0's rmse: 0.178187\n",
      "[50]\tvalid_0's rmse: 0.177793\n",
      "[51]\tvalid_0's rmse: 0.177276\n",
      "[52]\tvalid_0's rmse: 0.176848\n",
      "[53]\tvalid_0's rmse: 0.176395\n",
      "[54]\tvalid_0's rmse: 0.175912\n",
      "[55]\tvalid_0's rmse: 0.175626\n",
      "[56]\tvalid_0's rmse: 0.174984\n",
      "[57]\tvalid_0's rmse: 0.174767\n",
      "[58]\tvalid_0's rmse: 0.174558\n",
      "[59]\tvalid_0's rmse: 0.174161\n",
      "[60]\tvalid_0's rmse: 0.173953\n",
      "[61]\tvalid_0's rmse: 0.173787\n",
      "[62]\tvalid_0's rmse: 0.173494\n",
      "[63]\tvalid_0's rmse: 0.173379\n",
      "[64]\tvalid_0's rmse: 0.173221\n",
      "[65]\tvalid_0's rmse: 0.173007\n",
      "[66]\tvalid_0's rmse: 0.172859\n",
      "[67]\tvalid_0's rmse: 0.17279\n",
      "[68]\tvalid_0's rmse: 0.172705\n",
      "[69]\tvalid_0's rmse: 0.172622\n",
      "[70]\tvalid_0's rmse: 0.172391\n",
      "[71]\tvalid_0's rmse: 0.172212\n",
      "[72]\tvalid_0's rmse: 0.172158\n",
      "[73]\tvalid_0's rmse: 0.172115\n",
      "[74]\tvalid_0's rmse: 0.17201\n",
      "[75]\tvalid_0's rmse: 0.171963\n",
      "[76]\tvalid_0's rmse: 0.171902\n",
      "[77]\tvalid_0's rmse: 0.171874\n",
      "[78]\tvalid_0's rmse: 0.17179\n",
      "[79]\tvalid_0's rmse: 0.17172\n",
      "[80]\tvalid_0's rmse: 0.171649\n",
      "[81]\tvalid_0's rmse: 0.171634\n",
      "[82]\tvalid_0's rmse: 0.171606\n",
      "[83]\tvalid_0's rmse: 0.17155\n",
      "[84]\tvalid_0's rmse: 0.171493\n",
      "[85]\tvalid_0's rmse: 0.17147\n",
      "[86]\tvalid_0's rmse: 0.171424\n",
      "[87]\tvalid_0's rmse: 0.171407\n",
      "[88]\tvalid_0's rmse: 0.171396\n",
      "[89]\tvalid_0's rmse: 0.171342\n",
      "[90]\tvalid_0's rmse: 0.171311\n",
      "[91]\tvalid_0's rmse: 0.171302\n",
      "[92]\tvalid_0's rmse: 0.171294\n",
      "[93]\tvalid_0's rmse: 0.17128\n",
      "[94]\tvalid_0's rmse: 0.17127\n",
      "[95]\tvalid_0's rmse: 0.171253\n",
      "[96]\tvalid_0's rmse: 0.171216\n",
      "[97]\tvalid_0's rmse: 0.171185\n",
      "[98]\tvalid_0's rmse: 0.171179\n",
      "[99]\tvalid_0's rmse: 0.171174\n",
      "[100]\tvalid_0's rmse: 0.171159\n",
      "[101]\tvalid_0's rmse: 0.171153\n",
      "[102]\tvalid_0's rmse: 0.171134\n",
      "[103]\tvalid_0's rmse: 0.171125\n",
      "[104]\tvalid_0's rmse: 0.171114\n",
      "[105]\tvalid_0's rmse: 0.171109\n",
      "[106]\tvalid_0's rmse: 0.171121\n",
      "[107]\tvalid_0's rmse: 0.171116\n",
      "[108]\tvalid_0's rmse: 0.171116\n",
      "[109]\tvalid_0's rmse: 0.171105\n",
      "[110]\tvalid_0's rmse: 0.171101\n",
      "[111]\tvalid_0's rmse: 0.1711\n",
      "[112]\tvalid_0's rmse: 0.171103\n",
      "[113]\tvalid_0's rmse: 0.171096\n",
      "[114]\tvalid_0's rmse: 0.171102\n",
      "[115]\tvalid_0's rmse: 0.171106\n",
      "[116]\tvalid_0's rmse: 0.171093\n",
      "[117]\tvalid_0's rmse: 0.171087\n",
      "[118]\tvalid_0's rmse: 0.171082\n",
      "[119]\tvalid_0's rmse: 0.171087\n",
      "[120]\tvalid_0's rmse: 0.171084\n",
      "[121]\tvalid_0's rmse: 0.171084\n",
      "[122]\tvalid_0's rmse: 0.171072\n",
      "[123]\tvalid_0's rmse: 0.171069\n",
      "[124]\tvalid_0's rmse: 0.171058\n",
      "[125]\tvalid_0's rmse: 0.171058\n",
      "[126]\tvalid_0's rmse: 0.171061\n",
      "[127]\tvalid_0's rmse: 0.171071\n",
      "[128]\tvalid_0's rmse: 0.171058\n",
      "[129]\tvalid_0's rmse: 0.171052\n",
      "[130]\tvalid_0's rmse: 0.171045\n",
      "[131]\tvalid_0's rmse: 0.171041\n",
      "[132]\tvalid_0's rmse: 0.171037\n",
      "[133]\tvalid_0's rmse: 0.171035\n",
      "[134]\tvalid_0's rmse: 0.171037\n",
      "[135]\tvalid_0's rmse: 0.171039\n",
      "[136]\tvalid_0's rmse: 0.171045\n",
      "[137]\tvalid_0's rmse: 0.171042\n",
      "[138]\tvalid_0's rmse: 0.171035\n",
      "[139]\tvalid_0's rmse: 0.171037\n",
      "[140]\tvalid_0's rmse: 0.171037\n",
      "[141]\tvalid_0's rmse: 0.171039\n",
      "[142]\tvalid_0's rmse: 0.17104\n",
      "[143]\tvalid_0's rmse: 0.171045\n",
      "[144]\tvalid_0's rmse: 0.17104\n",
      "[145]\tvalid_0's rmse: 0.171037\n",
      "[146]\tvalid_0's rmse: 0.171046\n",
      "[147]\tvalid_0's rmse: 0.17105\n",
      "[148]\tvalid_0's rmse: 0.17106\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's rmse: 0.171035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_freq=15, boosting_type='gbdt', class_weight=None,\n",
       "       colsample_bytree=1.0, early_stopping_rounds=15, learning_rate=0.1,\n",
       "       max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "       min_split_gain=0.0, n_estimators=800, n_jobs=-1,\n",
       "       num_boost_round=500, num_leaves=300, objective='regression',\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, seed=42,\n",
       "       silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "       subsample_freq=1, task='train', verbose=0)"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb1 = LGBMRegressor(verbose = 0,\n",
    "                    task = 'train',\n",
    "                    boosting_type ='gbdt',\n",
    "                    objective = 'regression',\n",
    "                    num_leaves= 300,\n",
    "                    n_estimators = 800,\n",
    "                    bagging_freq=15,\n",
    "                    num_boost_round= 500,\n",
    "                    early_stopping_rounds= 15,\n",
    "                    seed=42\n",
    "                   )\n",
    "lgb1.fit(train.drop(['meanf_day', 'meanf_dayofweek',\n",
    "       'meanf_dayofyear', 'meanf_item', 'meanf_month', 'meanf_quarter',\n",
    "       'meanf_shop', 'meanf_weekofyear', 'meanf_year'], axis = 1), y_train, \n",
    "#         feval=lambda x, data: ('smape', smape(x, data.get_label()), False),\n",
    "        eval_metric='rmse',\n",
    "        eval_set=[(val.drop(['meanf_day', 'meanf_dayofweek',\n",
    "       'meanf_dayofyear', 'meanf_item', 'meanf_month', 'meanf_quarter',\n",
    "       'meanf_shop', 'meanf_weekofyear', 'meanf_year'], axis = 1), y_valid)],\n",
    "        verbose = True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_val_pr = lgb1.predict(val.drop(['meanf_day', 'meanf_dayofweek',\n",
    "       'meanf_dayofyear', 'meanf_item', 'meanf_month', 'meanf_quarter',\n",
    "       'meanf_shop', 'meanf_weekofyear', 'meanf_year'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.91563599350167"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape(np.expm1(lgb_val_pr), np.expm1(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_pred = lgb1.predict(test.drop(['meanf_day', 'meanf_dayofweek',\n",
    "       'meanf_dayofyear', 'meanf_item', 'meanf_month', 'meanf_quarter',\n",
    "       'meanf_shop', 'meanf_weekofyear', 'meanf_year'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=7.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 7.0)\n",
    "ridge.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.707361691561523"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_val_pr = ridge.predict(val)\n",
    "smape(np.expm1(ridge_val_pr), np.expm1(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ridge = ridge.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = pd.read_csv(\"sample_submission.csv\")\n",
    "subm['sales'] = (np.expm1(lgb_pred) + np.expm1(pr_ridge))/2\n",
    "pd.DataFrame(subm).to_csv('25_11_lgb_and_ridge_meanf_end_start_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
